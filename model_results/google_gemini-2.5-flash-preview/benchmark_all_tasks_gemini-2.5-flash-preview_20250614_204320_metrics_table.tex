\begin{table}[htbp]
\centering
\caption{Benchmark Results for Model: gemini-2.5-flash-preview, Task 13 (With Answer, Without Answer)}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{With Answer} & \textbf{Without Answer} \\
\midrule
Accuracy (\%) & 40.98 & 44.26 \\
Close Accuracy ($\pm$1 point) (\%) & N/A & N/A \\
Quality Score (\%) & 70.49 & 71.04 \\
Average Score Distance & 0.82 & 0.81 \\
Macro Precision (\%) & 41.43 & 41.85 \\
Macro Recall (\%) & 39.27 & 36.85 \\
Macro F1 (\%) & 40.08 & 38.09 \\
Evaluations (count) & 122 & 122 \\
Average Evaluation Time (s) & 14.92 & 16.08 \\
Total Cost (\$) & 0.30 & 0.32 \\
\bottomrule
\end{tabular}
\end{table}